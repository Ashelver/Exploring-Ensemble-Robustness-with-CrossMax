% ----------------- CHAPTER 5 -----------------
\chapter{Conclusions and Future Work}
\label{chap:conclusion & future work}

\paragraph{Conclusion}
This work systematically evaluated ensemble robustness under adversarial perturbations, comparing LP-trained and standard-trained models, different architectures, and ensemble aggregation methods such as CrossMax. A key practical insight is that users of ensemble models can monitor the volatility of \textit{CrossMax Confidence} as a diagnostic for adversarial sensitivity: ensembles exhibiting large fluctuations in CrossMax Confidence across perturbation levels tend to have weaker robustness, while more robust ensembles show remarkably stable CrossMax Confidence scores throughout.

Our experiments further reveal that while CrossMax-Ambiguous effectively leverages prediction ambiguity to improve robustness, the related method CrossMax-Exact underperforms due to the difficulty of selecting the optimal final prediction from ambiguous prediction sets. The current heuristic for choosing a prediction approximates random selection, limiting performance gains.

\paragraph{Future Work}
For future work, inspired by the cascading approach proposed by Wong et al.~\cite{wong2018scaling}, we propose to train specialized, robust binary classifiers dedicated to disambiguating prediction sets generated by CrossMax-Ambiguous. Because these binary models only need to be robust for two-class decisions rather than full multi-class classification, their training cost is lower and certified robustness easier to achieve. Leveraging these robust binary discriminators in a cascade to resolve ambiguous prediction sets promises to enhance the accuracy and robustness of CrossMax-Exact ensembles significantly. This direction opens a promising avenue for combining certified robustness techniques with ensemble uncertainty modeling to further advance provable defenses in adversarial settings.